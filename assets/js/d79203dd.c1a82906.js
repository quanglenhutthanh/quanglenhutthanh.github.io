"use strict";(self.webpackChunksrc=self.webpackChunksrc||[]).push([[5462],{1471:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>r,contentTitle:()=>c,default:()=>p,frontMatter:()=>o,metadata:()=>a,toc:()=>h});var s=i(5893),t=i(1151);const o={},c="Azure AI Speech service",a={id:"AI/Natural Language Processing/Azure AI Speech service",title:"Azure AI Speech service",description:"Created by: thanh quang le nhut",source:"@site/docs/AI/Natural Language Processing/Azure AI Speech service.md",sourceDirName:"AI/Natural Language Processing",slug:"/AI/Natural Language Processing/Azure AI Speech service",permalink:"/AI/Natural Language Processing/Azure AI Speech service",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Azure AI Language Service",permalink:"/AI/Natural Language Processing/Azure AI Language service"},next:{title:"Knowledge Mining",permalink:"/category/knowledge-mining"}},r={},h=[{value:"Speech to text",id:"speech-to-text",level:2},{value:"Text to speech",id:"text-to-speech",level:2},{value:"Speech Synthesis Markup Language",id:"speech-synthesis-markup-language",level:2},{value:"Translate speech with the Azure AI Speech service",id:"translate-speech-with-the-azure-ai-speech-service",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h1,{id:"azure-ai-speech-service",children:"Azure AI Speech service"}),"\n",(0,s.jsx)(n.p,{children:"Created by: thanh quang le nhut\nCreated time: January 2, 2024 10:43 AM"}),"\n",(0,s.jsx)(n.h1,{id:"azure-ai-speech-services",children:"Azure AI Speech services"}),"\n",(0,s.jsx)(n.p,{children:"Azure AI Speech provides APIs that you can use to build speech-enabled applications. This includes:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Speech to text: An API that enables speech recognition in which your application can accept spoken input."}),"\n",(0,s.jsx)(n.li,{children:"Text to speech: An API that enables speech synthesis in which your application can provide spoken output."}),"\n",(0,s.jsx)(n.li,{children:"Speech Translation: An API that you can use to translate spoken input into multiple languages."}),"\n",(0,s.jsx)(n.li,{children:"Speaker Recognition: An API that enables your application to recognize individual speakers based on their voice."}),"\n",(0,s.jsx)(n.li,{children:"Intent Recognition: An API that uses conversational language understanding to determine the semantic meaning of spoken input."}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"speech-to-text",children:"Speech to text"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image1.png",src:i(2907).Z+"",width:"790",height:"216"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"AudioConfig"})," represents audio input or output configuration. Audio input can be from a microphone, file, or input stream. Audio output can be to a speaker, audio file output as WAV format, or output stream."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SpeedRecognizer"})," transcribes speech into text."]}),"\n",(0,s.jsx)(n.h2,{id:"text-to-speech",children:"Text to speech"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image1.png",src:i(7493).Z+"",width:"786",height:"218"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"SpeechSynthesizer"})," performs speech synthesis to speaker, file, or other audio output streams."]}),"\n",(0,s.jsx)(n.h2,{id:"speech-synthesis-markup-language",children:"Speech Synthesis Markup Language"}),"\n",(0,s.jsx)(n.p,{children:"While the Azure AI Speech SDK enables you to submit plain text to be synthesized into speech (for example, by using the SpeakTextAsync() method), the service also supports an XML-based syntax for describing characteristics of the speech you want to generate. This Speech Synthesis Markup Language (SSML) syntax offers greater control over how the spoken output sounds, enabling you to:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'Specify a speaking style, such as "excited" or "cheerful" when using a neural voice.'}),"\n",(0,s.jsx)(n.li,{children:"Insert pauses or silence."}),"\n",(0,s.jsx)(n.li,{children:'Specify phonemes (phonetic pronunciations), for example to pronounce the text "SQL" as "sequel".'}),"\n",(0,s.jsx)(n.li,{children:"Adjust the prosody of the voice (affecting the pitch, timbre, and speaking rate)."}),"\n",(0,s.jsx)(n.li,{children:'Use common "say-as" rules, for example to specify that a given string should be expressed as a date, time, telephone number, or other form.'}),"\n",(0,s.jsx)(n.li,{children:"Insert recorded speech or audio, for example to include a standard recorded message or simulate background noise."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"For example, consider the following SSML:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image1.png",src:i(6684).Z+"",width:"865",height:"300"})}),"\n",(0,s.jsx)(n.p,{children:"To submit an SSML description to the Speech service, you can use the SpeakSsmlAsync() method, like this:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image1.png",src:i(771).Z+"",width:"379",height:"70"})}),"\n",(0,s.jsx)(n.h2,{id:"translate-speech-with-the-azure-ai-speech-service",children:"Translate speech with the Azure AI Speech service"}),"\n",(0,s.jsx)(n.p,{children:"The pattern for speech translation using the Azure AI Speech SDK is similar to speech recognition, with the addition of information about the source and target languages for translation:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"image1.png",src:i(1438).Z+"",width:"1429",height:"481"})}),"\n",(0,s.jsx)(n.h1,{id:"using-c-sdk",children:"Using C# SDK"}),"\n",(0,s.jsx)(n.p,{children:"dotnet add package Microsoft.CognitiveServices.Speech --version 1.30.0"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-C#",children:'using System;\nusing System.Media;\nusing System.Threading.Tasks;\nusing Microsoft.CognitiveServices.Speech;\nusing Microsoft.CognitiveServices.Speech.Audio;\nusing Microsoft.Extensions.Configuration;\n\n// Import namespaces\n\nnamespace speaking_clock\n{\n    class Program\n    {\n        private static SpeechConfig speechConfig;\n        static async Task Main(string[] args)\n        {\n            try\n            {\n                // Get config settings from AppSettings\n                IConfigurationBuilder builder = new ConfigurationBuilder().AddJsonFile("appsettings.json");\n                IConfigurationRoot configuration = builder.Build();\n                string aiSvcKey = configuration["SpeechKey"];\n                string aiSvcRegion = configuration["SpeechRegion"];\n\n                // Configure speech service\n                speechConfig = SpeechConfig.FromSubscription(aiSvcKey, aiSvcRegion);\n                \n\n                // Get spoken input\n                string command = "";\n                command = await TranscribeCommand();\n                if (command.ToLower()=="what time is it?")\n                {\n                    await TellTime();\n                }\n\n            }\n            catch (Exception ex)\n            {\n                Console.WriteLine(ex.Message);\n            }\n        }\n\n        static async Task<string> TranscribeCommand()\n        {\n            string command = "";\n\n            // Configure speech recognition\n\n            // Using audio file\n            string audioFile = "time.wav";\n            SoundPlayer wavPlayer = new SoundPlayer(audioFile);\n            wavPlayer.Play();\n            using AudioConfig audioConfig = AudioConfig.FromWavFileInput(audioFile);\n\n            // Using microphone\n            //using AudioConfig audioConfig = AudioConfig.FromDefaultMicrophoneInput();\n            //Console.WriteLine("Speak now...");\n            using SpeechRecognizer speechRecognizer = new SpeechRecognizer(speechConfig, audioConfig);\n\n            // Process speech input\n            SpeechRecognitionResult speech = await speechRecognizer.RecognizeOnceAsync();\n            if (speech.Reason == ResultReason.RecognizedSpeech)\n            {\n                command = speech.Text;\n                Console.WriteLine(command);\n            }\n            else\n            {\n                Console.WriteLine(speech.Reason);\n                if (speech.Reason == ResultReason.Canceled)\n                {\n                    var cancellation = CancellationDetails.FromResult(speech);\n                    Console.WriteLine(cancellation.Reason);\n                    Console.WriteLine(cancellation.ErrorDetails);\n                }\n            }\n\n            // Return the command\n            return command;\n        }\n\n        static async Task TellTime()\n        {\n            var now = DateTime.Now;\n            string responseText = "The time is " + now.Hour.ToString() + ":" + now.Minute.ToString("D2");\n\n            // Configure speech synthesis\n            speechConfig.SpeechSynthesisVoiceName = "en-GB-RyanNeural";\n            //speechConfig.SpeechSynthesisVoiceName = "en-GB-LibbyNeural"; \n            using SpeechSynthesizer speechSynthesizer = new SpeechSynthesizer(speechConfig);\n\n            // Synthesize spoken output\n            SpeechSynthesisResult speak = await speechSynthesizer.SpeakTextAsync(responseText);\n            if (speak.Reason != ResultReason.SynthesizingAudioCompleted)\n            {\n                Console.WriteLine(speak.Reason);\n            }\n\n            // Print the response\n            Console.WriteLine(responseText);\n        }\n\n    }\n}\n'})})]})}function p(e={}){const{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},2907:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/image1-73ee33de4b69986179d7672c4ec3a61e.png"},7493:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/image2-4709f76a84679783e3d26a2e3e4f195b.png"},6684:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/image3-411b8967b3c86687020bcfbb017bf284.png"},771:(e,n,i)=>{i.d(n,{Z:()=>s});const s="data:image/png;base64,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"},1438:(e,n,i)=>{i.d(n,{Z:()=>s});const s=i.p+"assets/images/image5-69b365e79b768016d08c82e788e48050.png"},1151:(e,n,i)=>{i.d(n,{Z:()=>a,a:()=>c});var s=i(7294);const t={},o=s.createContext(t);function c(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);